---
layout: post
title:  "All Algorithmic Decisions are Human Decisions: How to discuss the intentionality of technology."
date:   2019-04-09 12:00:00 +0200
categories: philosophy
---


Keypoints:

a) Discussing systems as if they have an intention is misleading and takes responsibility for morally questionnable choices away from humans. Example: Filter-Bubbles, Data breaches, self-driving cars

b) Argument: Every decision that is implemented in a computer system can be traced back to an individual that implemented it.

c) But an individual might not be responsible for the choice that let to this implementation ("I was just following the business requirements"). Furthermore, in modern development practice a system is formed by many different entities, over a timespan, often in relation to other system that it uses or integrates.

d) Could we somehow lessen this gap by giving companies an intention? Or have we then just shifted the problem one step down/up?

e) How can we discuss the design goals of complex systems without giving them a mystical sense of intentionality?

